# UK Global Talent Visa RAG Chatbot

An AI-powered chatbot built using Azure OpenAI, ChromaDB, FastAPI, and a custom Retrieval-Augmented Generation (RAG) pipeline.

This system answers questions strictly based on provided UK Global Talent Visa documentation, ensuring grounded and non-hallucinated responses.

---

## ğŸš€ Features

- Azure OpenAI Embeddings (`text-embedding-3-small`)
- Azure OpenAI Chat Model (`gpt-4o-mini`)
- ChromaDB persistent vector database
- Strict context-based answering (No hallucination)
- FastAPI backend with REST endpoint
- Clean HTML/CSS/JS frontend
- Modular RAG architecture

---

## ğŸ§  Architecture

PDF Data
â†“
Azure Embeddings (text-embedding-3-small)
â†“
ChromaDB (Persistent Vector Store)
â†“
Retriever (Semantic Search)
â†“
Generator (gpt-4o-mini)
â†“
FastAPI (/chat endpoint)
â†“
Frontend UI



---

## ğŸ“ Project Structure

backend/
â”‚
â”œâ”€â”€ main.py # FastAPI entry point
â”œâ”€â”€ rag/
â”‚ â”œâ”€â”€ ingest.py # PDF ingestion & embedding storage
â”‚ â”œâ”€â”€ retriever.py # Semantic search layer
â”‚ â”œâ”€â”€ generator.py # Grounded answer generation
â”‚ â””â”€â”€ pipeline.py # RAG orchestration layer
â”‚
â””â”€â”€ db/ # ChromaDB storage (ignored in git)

frontend/
â”œâ”€â”€ index.html
â”œâ”€â”€ style.css
â””â”€â”€ script.js

.env # Environment variables (not committed)
requirements.txt
README.md


Setup Instructions - 


1ï¸âƒ£ Clone the Repository
git clone <your-repo-url>
cd <project-folder>



2ï¸âƒ£ Create Virtual Environment
Windows
python -m venv venv
venv\Scripts\activate
Mac / Linux
python3 -m venv venv
source venv/bin/activate



3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt




4ï¸âƒ£ Configure Environment Variables

Create a .env file in the project root:

AZURE_OPENAI_API_KEY=your_azure_api_key
AZURE_OPENAI_ENDPOINT=https://your-resource-name.cognitiveservices.azure.com/
AZURE_OPENAI_API_VERSION=2023-05-15

âš ï¸ Do NOT commit .env to GitHub.

Make sure .gitignore contains:

.env
venv/
backend/db/chroma_db/
__pycache__/




5ï¸âƒ£ Ingest the Data (Important Step)

Before running the server, generate embeddings and store them in ChromaDB:

python backend/rag/ingest.py

This will:

Extract text from PDF

Generate embeddings using Azure OpenAI

Store vectors in ChromaDB

You should see:

Ingestion complete!



6ï¸âƒ£ Run the Backend Server
uvicorn backend.main:app --reload

Server will start at:

http://127.0.0.1:8000

Swagger Docs available at:

http://127.0.0.1:8000/docs


7ï¸âƒ£ Test API

Use Swagger UI or send request:

POST /chat

Request Body:

{
  "message": "What is the minimum age?"
}


8ï¸âƒ£ Run Frontend

Open:

frontend/index.html

